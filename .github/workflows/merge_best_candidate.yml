name: Merge Best Algorithm Candidate

# Run after evaluations complete or manually
on:
  # Run when evaluate_candidates workflow completes
  workflow_run:
    workflows: ["Evaluate Algorithm Candidates"]
    types:
      - completed
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  compare-and-merge:
    runs-on: ubuntu-latest
    # Only run if the evaluation workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history and branches
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Download all artifacts
        uses: dawidd6/action-download-artifact@v2
        with:
          workflow: evaluate_candidates.yml
          workflow_conclusion: success
          path: artifacts
      
      # Set parameters based on the event type
      - name: Set parameters
        id: params
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "benchmark_dir=${{ github.event.inputs.benchmark_dir }}" >> $GITHUB_OUTPUT
            echo "target_branch=${{ github.event.inputs.target_branch }}" >> $GITHUB_OUTPUT
            echo "metric=${{ github.event.inputs.metric }}" >> $GITHUB_OUTPUT
            echo "dry_run=${{ github.event.inputs.dry_run }}" >> $GITHUB_OUTPUT
          else
            echo "benchmark_dir=benchmark-results" >> $GITHUB_OUTPUT
            echo "target_branch=experiment_ensemble" >> $GITHUB_OUTPUT
            echo "metric=accuracy" >> $GITHUB_OUTPUT
            echo "dry_run=false" >> $GITHUB_OUTPUT
          fi
      
      # Set up git identity for merge
      - name: Configure Git
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
      
      # Run the merge script
      - name: Find best branch
        id: find-best
        run: |
          # Create script to find best branch
          cat > find_best_branch.py << 'EOF'
          import json
          import os
          import glob
          
          def find_best_branch():
              metrics_files = glob.glob('artifacts/metrics-*/benchmark_metrics.json')
              
              if not metrics_files:
                  print("No metrics files found")
                  return None, 0
              
              best_branch = None
              best_score = float('-inf')
              
              for metrics_file in metrics_files:
                  # Extract branch name from directory pattern artifacts/metrics-{branch}/...
                  branch = metrics_file.split('/')[1].replace('metrics-', '')
                  
                  try:
                      with open(metrics_file, 'r') as f:
                          data = json.load(f)
                          score = data.get('total_score', 0)
                          accuracy = data.get('accuracy', 0)
                          
                          # Can adjust scoring logic as needed
                          total_score = score if score else accuracy
                          
                          print(f"Branch {branch}: Score = {total_score}")
                          
                          if total_score > best_score:
                              best_score = total_score
                              best_branch = branch
                  except Exception as e:
                      print(f"Error processing {metrics_file}: {e}")
              
              return best_branch, best_score
          
          if __name__ == "__main__":
              best_branch, best_score = find_best_branch()
              if best_branch:
                  print(f"::set-output name=best_branch::{best_branch}")
                  print(f"::set-output name=best_score::{best_score}")
                  # Also use the new GitHub Actions output syntax
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write(f"best_branch={best_branch}\n")
                      f.write(f"best_score={best_score}\n")
              else:
                  print("No best branch found")
                  exit(1)
          EOF
          
          python find_best_branch.py
      
      - name: Create comparison PR
        if: steps.find-best.outputs.best_branch != ''
        run: |
          BEST_BRANCH="${{ steps.find-best.outputs.best_branch }}"
          BEST_SCORE="${{ steps.find-best.outputs.best_score }}"
          PR_BRANCH="merge-best-candidate-${GITHUB_RUN_ID}"
          
          echo "Best branch: $BEST_BRANCH with score: $BEST_SCORE"
          
          # Create a new branch for the PR
          git checkout -b $PR_BRANCH
          
          # Copy benchmark report from the best branch
          cp "artifacts/metrics-$BEST_BRANCH/benchmark_report.md" ./best_candidate_report.md
          
          # Create summary markdown file
          cat > best_candidate_summary.md << EOF
          # Best Algorithm Candidate
          
          This PR merges the best performing algorithm candidate from the AlphaEvolve workflow.
          
          - **Branch:** $BEST_BRANCH
          - **Score:** $BEST_SCORE
          
          See [best_candidate_report.md](./best_candidate_report.md) for detailed metrics.
          EOF
          
          # Add files to git
          git add best_candidate_report.md best_candidate_summary.md
          git commit -m "Add benchmark reports for best candidate ($BEST_BRANCH)"
          
          # Push branch
          git push origin $PR_BRANCH
          
          # Create PR using gh CLI
          gh pr create \
            --title "Merge best algorithm candidate: $BEST_BRANCH" \
            --body-file best_candidate_summary.md \
            --base main \
            --head $PR_BRANCH
      
      - name: Auto-merge if threshold met
        if: steps.find-best.outputs.best_branch != '' && steps.find-best.outputs.best_score >= 0.95
        run: |
          BEST_BRANCH="${{ steps.find-best.outputs.best_branch }}"
          
          # Checkout main branch
          git checkout main
          
          # Merge the best branch with a merge commit
          git merge --no-ff $BEST_BRANCH -m "Auto-merge best algorithm: $BEST_BRANCH (score: ${{ steps.find-best.outputs.best_score }})"
          
          # Push to main
          git push origin main
      
      # Create summary report of the merge decision
      - name: Create summary
        run: |
          echo "# AlphaEvolve - Merge Decision" > merge_summary.md
          echo "" >> merge_summary.md
          echo "## Parameters" >> merge_summary.md
          echo "- Target Branch: ${{ steps.params.outputs.target_branch }}" >> merge_summary.md
          echo "- Selection Metric: ${{ steps.params.outputs.metric }}" >> merge_summary.md
          echo "- Dry Run: ${{ steps.params.outputs.dry_run }}" >> merge_summary.md
          echo "" >> merge_summary.md
          echo "## Results" >> merge_summary.md
          echo "See job logs for detailed results and merge status." >> merge_summary.md
          
          cat merge_summary.md
      
      # Upload merge summary
      - name: Upload merge summary
        uses: actions/upload-artifact@v3
        with:
          name: merge-summary
          path: merge_summary.md 